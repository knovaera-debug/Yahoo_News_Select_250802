import chromedriver_autoinstaller
chromedriver_autoinstaller.install()

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import os
import time

# âœ… Googleèªè¨¼æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€
credentials_json = os.getenv('GOOGLE_CREDENTIALS')
if credentials_json is None:
    raise ValueError("ç’°å¢ƒå¤‰æ•° GOOGLE_CREDENTIALS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

credentials_dict = json.loads(credentials_json)
scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
credentials = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, scope)
gc = gspread.authorize(credentials)

# âœ… Chromeè¨­å®š
options = Options()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev_shm_usage')
driver = webdriver.Chrome(options=options)

try:
    # âœ… å…¥åŠ›ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰URLã‚’ã™ã¹ã¦å–å¾—
    INPUT_SPREADSHEET_ID = '1yjHpQMHfJt7shjqZ6SYQNNlHougbrw0ZCgWpFUgv3Sc'
    input_ws = gc.open_by_key(INPUT_SPREADSHEET_ID).worksheet('URLS')
    # A2ä»¥é™ã®Aåˆ—ã®å€¤ã‚’ã™ã¹ã¦å–å¾—
    urls = input_ws.col_values(1)[1:]

    # âœ… å‡ºåŠ›ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã
    OUTPUT_SPREADSHEET_ID = '1ff9j8Dr2G6UO2GjsLNpgC8bW0KJmX994iJruw4X_qVM'
    output_ws = gc.open_by_key(OUTPUT_SPREADSHEET_ID).worksheet('Base')

    for base_url in urls:
        if not base_url:
            continue
            
        # æœ€åˆã®ãƒšãƒ¼ã‚¸ï¼ˆpage=1ï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã¨æŠ•ç¨¿æ—¥æ™‚ã‚’å–å¾—
        try:
            driver.get(base_url)
            time.sleep(3) # ãƒšãƒ¼ã‚¸ã®æç”»ã‚’å¾…ã¤ãŸã‚ã«ä¸€æ™‚åœæ­¢ã‚’è¿½åŠ 
            initial_soup = BeautifulSoup(driver.page_source, 'html.parser')
            
            # âœ… B3ã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ›¸ãè¾¼ã¿
            title_tag = initial_soup.find('h1')
            news_title = title_tag.text.strip() if title_tag else 'å–å¾—ä¸å¯'
            output_ws.update('B3', [[news_title]])
            print(f"âœ… B3ã‚»ãƒ«ã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ›¸ãè¾¼ã¿ã¾ã—ãŸ: {news_title}")

            # âœ… B4ã«URLã‚’æ›¸ãè¾¼ã¿
            output_ws.update('B4', [[base_url]])
            print(f"âœ… B4ã‚»ãƒ«ã«URLã‚’æ›¸ãè¾¼ã¿ã¾ã—ãŸ: {base_url}")

            # âœ… B5ã«æŠ•ç¨¿æ—¥æ™‚ã‚’æ›¸ãè¾¼ã¿
            date_tag = initial_soup.find('time')
            news_date = date_tag.text.strip() if date_tag else 'å–å¾—ä¸å¯'
            output_ws.update('B5', [[news_date]])
            print(f"âœ… B5ã‚»ãƒ«ã«æŠ•ç¨¿æ—¥æ™‚ã‚’æ›¸ãè¾¼ã¿ã¾ã—ãŸ: {news_date}")
            
        except Exception as e:
            print(f"âš ï¸ ã‚¿ã‚¤ãƒˆãƒ«ã€URLã€æŠ•ç¨¿æ—¥æ™‚ã®å–å¾—ã¾ãŸã¯æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            
        # è¨˜äº‹æœ¬æ–‡ï¼ˆè¤‡æ•°ãƒšãƒ¼ã‚¸å¯¾å¿œï¼‰ã®å–å¾—ã¨æ›¸ãè¾¼ã¿
        page_number = 1
        while True:
            # ãƒšãƒ¼ã‚¸ç•ªå·ã«å¿œã˜ã¦URLã‚’æ§‹ç¯‰
            if page_number == 1:
                article_url = base_url
            else:
                article_url = f"{base_url}?page={page_number}"

            print(f"ğŸ” URL: {article_url} ã®è¨˜äº‹æœ¬æ–‡ã‚’å–å¾—ã—ã¾ã™ã€‚")

            article_body = ""
            driver.get(article_url)

            if "æŒ‡å®šã•ã‚ŒãŸURLã¯å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚" in driver.page_source:
                print(f"â„¹ï¸ {page_number}ãƒšãƒ¼ã‚¸ç›®ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break

            try:
                WebDriverWait(driver, 30).until(
                    EC.presence_of_element_located((By.TAG_NAME, 'article'))
                )
                article_soup = BeautifulSoup(driver.page_source, 'html.parser')
                article_container = article_soup.find('article')
                if article_container:
                    article_body = article_container.get_text(separator='\n', strip=True)
                    print(f"âœ… {page_number}ãƒšãƒ¼ã‚¸ç›®ã®è¨˜äº‹æœ¬æ–‡ã®å–å¾—ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
                    print(f"ã€€å–å¾—ã—ãŸæœ¬æ–‡ã®æ–‡å­—æ•°: {len(article_body)}æ–‡å­—")
                    print(f"ã€€å–å¾—ã—ãŸæœ¬æ–‡ã®å†’é ­: {article_body[:50]}...")
                else:
                    raise NoSuchElementException(f"{page_number}ãƒšãƒ¼ã‚¸ç›®ã®è¨˜äº‹æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            except (TimeoutException, NoSuchElementException) as e:
                print(f"âš ï¸ {page_number}ãƒšãƒ¼ã‚¸ç›®ã®è¨˜äº‹æœ¬æ–‡ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                print("--- ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆHTMLã‚½ãƒ¼ã‚¹ã®å†’é ­500æ–‡å­—ï¼‰ ---")
                print(driver.page_source[:500])
                print("-------------------------------------------------")
                article_body = "è¨˜äº‹æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

            try:
                row_to_write = f'B{5 + page_number}'

                if len(article_body) > 50000:
                    truncated_body = article_body[:50000] + "..."
                    output_ws.update(row_to_write, [[truncated_body]])
                    print(f"âœ… è¨˜äº‹æœ¬æ–‡ãŒé•·ã„ãŸã‚ã€50000æ–‡å­—ã«åˆ¶é™ã—ã¦{row_to_write}ã‚»ãƒ«ã«æ›¸ãè¾¼ã¿ã¾ã—ãŸã€‚")
                else:
                    output_ws.update(row_to_write, [[article_body]])
                    print(f"âœ… {row_to_write}ã‚»ãƒ«ã«è¨˜äº‹æœ¬æ–‡ã‚’æ›¸ãè¾¼ã¿ã¾ã—ãŸã€‚")
            except Exception as e:
                print(f"âš ï¸ æ›¸ãè¾¼ã¿å¤±æ•—: {e}")
            
            page_number += 1

finally:
    driver.quit()
    print("âœ… å®Œäº†")
